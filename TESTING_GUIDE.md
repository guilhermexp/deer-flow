# üß™ Guia de Testes - DeerFlow

Este documento fornece informa√ß√µes completas sobre a implementa√ß√£o e execu√ß√£o de testes no projeto DeerFlow.

## üìã Resumo da Implementa√ß√£o

### Framework de Testes Escolhido

**Backend (Python):**
- **Framework**: pytest + pytest-cov
- **Motivo**: Padr√£o da ind√∫stria para Python, excelente suporte async, rico ecossistema de plugins

**Frontend (Next.js):**
- **Framework**: Vitest + @testing-library/react
- **Motivo**: Mais r√°pido que Jest, melhor suporte a ESM, integra√ß√£o nativa com Vite

## üéØ Cobertura de Testes Atual

### Backend (Python)
- **Cobertura M√≠nima**: 25% (configurada no pyproject.toml)
- **Testes Implementados**: 525 testes coletados
- **Status**: ‚ö†Ô∏è 55 falhas, 465 aprovados, 5 ignorados

### Frontend (Next.js)
- **Cobertura M√≠nima**: 75% linhas, 70% branches/functions
- **Testes Implementados**: 16 testes
- **Status**: ‚úÖ 15 aprovados, 1 falha

## üöÄ Comandos para Executar Testes

### Backend

```bash
# Executar todos os testes
make test
uv run pytest tests/

# Executar com cobertura
make coverage
uv run pytest --cov=src tests/ --cov-report=term-missing

# Executar testes espec√≠ficos
uv run pytest tests/unit/utils/test_json_utils.py
uv run pytest tests/integration/test_api_endpoints.py

# Executar em modo verbose
uv run pytest tests/ -v

# Executar apenas testes que falharam na √∫ltima execu√ß√£o
uv run pytest --lf

# Executar testes em paralelo (se pytest-xdist estiver instalado)
uv run pytest tests/ -n auto
```

### Frontend

```bash
# Entrar no diret√≥rio web
cd web

# Executar todos os testes
pnpm test:run

# Executar com cobertura
pnpm test:coverage

# Executar em modo watch (desenvolvimento)
pnpm test:watch

# Executar testes com UI interativa
pnpm test:ui

# Executar testes espec√≠ficos
pnpm vitest run src/components/ui/__tests__/liquid-glass-card.test.tsx
```

### Comandos Unificados (Makefile)

```bash
# Executar todos os testes (backend + frontend)
make test-all

# Executar apenas testes frontend com cobertura
make test-frontend

# Lint + testes + build frontend
make lint-frontend
```

## üìÅ Estrutura de Testes

### Backend
```
tests/
‚îú‚îÄ‚îÄ integration/          # Testes de integra√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ test_api_endpoints.py
‚îÇ   ‚îú‚îÄ‚îÄ test_nodes.py
‚îÇ   ‚îî‚îÄ‚îÄ test_crawler.py
‚îú‚îÄ‚îÄ unit/                 # Testes unit√°rios
‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_json_utils.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_json_utils_enhanced.py
‚îÇ   ‚îú‚îÄ‚îÄ llms/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_llm.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_llm_enhanced.py
‚îÇ   ‚îî‚îÄ‚îÄ server/
‚îî‚îÄ‚îÄ server/               # Testes espec√≠ficos do servidor
```

### Frontend
```
web/src/
‚îú‚îÄ‚îÄ components/ui/__tests__/
‚îÇ   ‚îî‚îÄ‚îÄ liquid-glass-card.test.tsx
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ store/__tests__/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ events.test.ts
‚îÇ   ‚îî‚îÄ‚îÄ utils/__tests__/
‚îÇ       ‚îî‚îÄ‚îÄ json.test.ts
‚îú‚îÄ‚îÄ lib/__tests__/
‚îÇ   ‚îî‚îÄ‚îÄ id-converter.test.ts
‚îî‚îÄ‚îÄ test/
    ‚îî‚îÄ‚îÄ setup.ts          # Configura√ß√£o global dos testes
```

## üîß Configura√ß√£o de Testes

### Backend (pyproject.toml)
```toml
[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
addopts = "-v --cov=src --cov-report=term-missing"
filterwarnings = [
    "ignore::DeprecationWarning",
    "ignore::UserWarning",
]

[tool.coverage.report]
fail_under = 25
```

### Frontend (vitest.config.ts)
```typescript
export default defineConfig({
  test: {
    environment: "jsdom",
    globals: true,
    setupFiles: "./src/test/setup.ts",
    coverage: {
      provider: 'v8',
      reporter: ['text', 'json', 'html'],
      thresholds: {
        global: {
          branches: 70,
          functions: 70,
          lines: 75,
          statements: 75
        }
      }
    }
  }
})
```

## üìä Tipos de Testes Implementados

### 1. Testes Unit√°rios

**Backend:**
- ‚úÖ `test_json_utils_enhanced.py` - Testes para utilit√°rios JSON
- ‚úÖ `test_llm_enhanced.py` - Testes para gerenciamento de LLMs

**Frontend:**
- ‚úÖ `liquid-glass-card.test.tsx` - Componente UI
- ‚úÖ `json.test.ts` - Utilit√°rio de parsing JSON
- ‚úÖ `events.test.ts` - Sistema de eventos
- ‚úÖ `id-converter.test.ts` - Convers√£o de IDs

### 2. Testes de Integra√ß√£o

**Backend:**
- ‚úÖ `test_api_endpoints.py` - Endpoints da API FastAPI
- üîÑ `test_nodes.py` - Nodes do LangGraph (alguns falhando)
- ‚ö†Ô∏è `test_crawler.py` - Web crawler (problemas de depend√™ncia)

### 3. Testes de Componentes

**Frontend:**
- ‚úÖ Testes de renderiza√ß√£o e props de componentes React
- ‚úÖ Testes de intera√ß√£o de usu√°rio
- ‚úÖ Testes de acessibilidade b√°sica

## ‚ö†Ô∏è Problemas Conhecidos e Pr√≥ximos Passos

### Problemas Backend
1. **55 testes falhando** - Principalmente relacionados a:
   - Configura√ß√£o de autentica√ß√£o (Clerk)
   - Depend√™ncias de LLM n√£o configuradas
   - Problemas de Node.js para crawler

### Problemas Frontend
1. **1 teste falhando** - Sistema de eventos:
   - Captura de erros em listeners precisa ser melhorada

### Pr√≥ximos Passos para Expans√£o

#### Curto Prazo (1-2 semanas)
1. **Corrigir testes falhando**:
   - Configurar mocks adequados para depend√™ncias externas
   - Resolver problemas de autentica√ß√£o nos testes
   - Corrigir depend√™ncias Node.js do crawler

2. **Aumentar cobertura frontend**:
   - Testes para componentes deer-flow espec√≠ficos
   - Testes para stores Zustand
   - Testes para hooks customizados

3. **Melhorar testes de integra√ß√£o**:
   - Testes E2E com Playwright
   - Testes de API completos
   - Testes de fluxos de trabalho

#### M√©dio Prazo (1 m√™s)
1. **Testes de Performance**:
   - Testes de carga para API
   - Testes de renderiza√ß√£o frontend
   - Benchmarks de LLM

2. **Testes de Seguran√ßa**:
   - Valida√ß√£o de inputs
   - Testes de autoriza√ß√£o
   - Sanitiza√ß√£o de dados

3. **Testes Visuais**:
   - Screenshot testing
   - Regression visual
   - Testes de responsividade

#### Longo Prazo (3+ meses)
1. **CI/CD Integration**:
   - Pipeline automatizada
   - Quality gates
   - Deploy condicional

2. **Testes de Acessibilidade**:
   - Compliance WCAG
   - Screen reader testing
   - Keyboard navigation

## üéØ Metas de Cobertura

### Atual
- **Backend**: 25% (m√≠nimo configurado)
- **Frontend**: 75% (m√≠nimo configurado)

### Meta 6 meses
- **Backend**: 60%
- **Frontend**: 85%
- **E2E**: Cobertura completa dos fluxos principais

### Meta 1 ano
- **Backend**: 80%
- **Frontend**: 90%
- **E2E**: Cobertura completa + testes de performance
- **Zero testes falhando** em ambiente est√°vel

## üîç Como Contribuir com Testes

### Escrevendo Novos Testes

1. **Backend**: Seguir padr√£o pytest
```python
def test_function_name():
    # Arrange
    input_data = "test"

    # Act
    result = function_under_test(input_data)

    # Assert
    assert result == expected_output
```

2. **Frontend**: Seguir padr√£o Vitest + Testing Library
```typescript
describe('ComponentName', () => {
  it('should render correctly', () => {
    render(<ComponentName />);
    expect(screen.getByText('Expected Text')).toBeInTheDocument();
  });
});
```

### Conven√ß√µes

- Nomes de arquivo: `test_*.py` (backend), `*.test.ts(x)` (frontend)
- Um arquivo de teste por m√≥dulo/componente
- Mocks em arquivos separados quando complexos
- Coment√°rios explicando cen√°rios de teste n√£o √≥bvios

## üìà Monitoramento e Relat√≥rios

### Relat√≥rios de Cobertura
- **Backend**: Terminal + XML para CI/CD
- **Frontend**: Terminal + HTML + JSON

### Localiza√ß√£o dos Relat√≥rios
- **Backend**: Exibido no terminal ap√≥s execu√ß√£o
- **Frontend**: `web/coverage/` (HTML) ap√≥s `pnpm test:coverage`

### M√©tricas Acompanhadas
- Cobertura de linhas
- Cobertura de branches
- Cobertura de fun√ß√µes
- Tempo de execu√ß√£o dos testes
- Taxa de sucesso/falha

---

**√öltima atualiza√ß√£o**: 19 de Outubro de 2025
**Respons√°vel**: Claude Code
**Status**: ‚úÖ Implementa√ß√£o b√°sica completa